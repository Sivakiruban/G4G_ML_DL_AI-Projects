{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CSDkcmvSSMl"
      },
      "source": [
        "# Intelligent document processing\n",
        "\n",
        "Helps in processign unstructured and semi-structured data in documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvfjWLjnhnKo"
      },
      "source": [
        "For testing purposes - we will be using only a small set (5) of resumes.\n",
        "\n",
        "Resumes were obtained from: [Kaggle](https://www.kaggle.com/datasets/snehaanbhawal/resume-dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YitMhpPbzXtP"
      },
      "source": [
        "## Installations and processing functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HEZWYgdR4Xb",
        "outputId": "93b27b91-8e90-442c-c012-e47a91da33b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.6)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Collecting poppler-utils\n",
            "  Downloading poppler_utils-0.1.0-py3-none-any.whl.metadata (883 bytes)\n",
            "Requirement already satisfied: Click>=7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from poppler-utils) (8.2.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Click>=7.0->poppler-utils) (0.4.6)\n",
            "Downloading poppler_utils-0.1.0-py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: poppler-utils\n",
            "Successfully installed poppler-utils-0.1.0\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (11.3.0)\n",
            "Requirement already satisfied: packaging>=21.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytesseract) (24.2)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "! pip install opencv-python matplotlib numpy pdf2image\n",
        "! pip install poppler-utils\n",
        "! pip install pytesseract pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "irziWzNQvXpH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yU6NIO5Fvi5Y"
      },
      "outputs": [],
      "source": [
        "def display_image(image, title=\"Image\"):\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5v6jXn-cv1p1"
      },
      "outputs": [],
      "source": [
        "# Convert the image to grayscale\n",
        "def convert_to_grayscale(image):\n",
        "  return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "def reduce_noise(gray_image):\n",
        "  return cv2.GaussianBlur(gray_image, (5, 5), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rgtpAOIFv3uI"
      },
      "outputs": [],
      "source": [
        "def binarize_image(blur_reduced_image):\n",
        "  return cv2.adaptiveThreshold(\n",
        "    blur_reduced_image,\n",
        "    255,\n",
        "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "    cv2.THRESH_BINARY_INV, # Invert the colors (text becomes white)\n",
        "    11, # Block size\n",
        "    4  # Constant C\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a_0OWuTLv5wg"
      },
      "outputs": [],
      "source": [
        "def deskew_image(image):\n",
        "    \"\"\"\n",
        "    Corrects the skew of an image by finding the minimum area rectangle\n",
        "    of the text block and rotating accordingly.\n",
        "    \"\"\"\n",
        "    # Find all non-zero (white) pixels\n",
        "    coords = cv2.findNonZero(image)\n",
        "\n",
        "    # Get the minimum area bounding rectangle\n",
        "    # It returns (center(x,y), (width, height), angle of rotation)\n",
        "    rect = cv2.minAreaRect(coords)\n",
        "    angle = rect[-1] - 90\n",
        "\n",
        "    # The `cv2.minAreaRect` angle has a specific range.\n",
        "    # We need to adjust it for our rotation.\n",
        "    if angle < -45:\n",
        "        angle = -(90 + angle)\n",
        "    else:\n",
        "        angle = angle\n",
        "\n",
        "    # Get the rotation matrix and rotate the image\n",
        "    (h, w) = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image, M, (w, h),\n",
        "                             flags=cv2.INTER_CUBIC,\n",
        "                             borderMode=cv2.BORDER_REPLICATE)\n",
        "    print(f\"Detected skew angle: {angle:.2f} degrees\")\n",
        "\n",
        "    # Now, rotate the original grayscale image by the same angle\n",
        "    (h, w) = rotated.shape\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    deskewed_gray = cv2.warpAffine(rotated, M, (w, h),\n",
        "                                  flags=cv2.INTER_CUBIC,\n",
        "                                  borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "    return deskewed_gray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EcHux5Fgv6k3"
      },
      "outputs": [],
      "source": [
        "def process_one_image(image):\n",
        "  image = convert_to_grayscale(image)\n",
        "  print(\"Converted image to grayscale..\")\n",
        "  image = reduce_noise(image)\n",
        "  print(\"Reduced noise in the image..\")\n",
        "  image = binarize_image(image)\n",
        "  print(\"Binarized the image..\")\n",
        "  image = deskew_image(image)\n",
        "  print(\"Corrected image orientation..\")\n",
        "  return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyLbWt9UwG8S"
      },
      "source": [
        "## Prepping the resumes for extraction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLW65XkMwMpH",
        "outputId": "ef42acb9-2d52-4c6e-bb3e-23cb3535ce86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing resume: Resume1.pdf\n",
            "Error processing Resume1.pdf: Unable to get page count. Is poppler installed and in PATH?\n",
            "--------------------------------------------------\n",
            "Processing resume: Resume2.pdf\n",
            "Error processing Resume2.pdf: Unable to get page count. Is poppler installed and in PATH?\n",
            "--------------------------------------------------\n",
            "Processing resume: Resume3.pdf\n",
            "Error processing Resume3.pdf: Unable to get page count. Is poppler installed and in PATH?\n",
            "--------------------------------------------------\n",
            "Processing resume: Resume4.pdf\n",
            "Error processing Resume4.pdf: Unable to get page count. Is poppler installed and in PATH?\n",
            "--------------------------------------------------\n",
            "Processing resume: Resume5.pdf\n",
            "Error processing Resume5.pdf: Unable to get page count. Is poppler installed and in PATH?\n",
            "--------------------------------------------------\n",
            "Processing images is completed.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os\n",
        "import zipfile\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "output_folder_path = \"processed_images\"\n",
        "\n",
        "if os.makedirs(output_folder_path, exist_ok=True):\n",
        "  print(f\"Created folder: {output_folder_path}\")\n",
        "\n",
        "resumes_folder = 'Resumes'\n",
        "\n",
        "for resume_name in os.listdir(resumes_folder):\n",
        "  if resume_name.endswith('.pdf'):\n",
        "    print(f\"Processing resume: {resume_name}\")\n",
        "    resume_path = os.path.join(resumes_folder, resume_name)\n",
        "\n",
        "    # Convert the first page of the PDF to an image\n",
        "    try:\n",
        "      pages = convert_from_path(resume_path, first_page=1, last_page=1)\n",
        "      if pages:\n",
        "        image = cv2.cvtColor(np.array(pages[0]), cv2.COLOR_RGB2BGR)\n",
        "        processed_image = process_one_image(image)\n",
        "        output_path = os.path.join(output_folder_path, resume_name.replace('.pdf', '.png'))\n",
        "        cv2.imwrite(output_path, processed_image)\n",
        "        print(f\"Saved processed image to: {output_path}\")\n",
        "        print(\"-\"*50)\n",
        "      else:\n",
        "        print(f\"Could not convert the first page of {resume_name} to an image.\")\n",
        "        print(\"-\"*50)\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing {resume_name}: {e}\")\n",
        "      print(\"-\"*50)\n",
        "\n",
        "\n",
        "print(\"Processing images is completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YH7EWVPzPlu"
      },
      "source": [
        "## Text extraction using Tesseract:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68l4pDBxt4x",
        "outputId": "b3bc5d8a-da2f-4e41-a967-9b4a0fd285f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images in folder: 5\n",
            "Processing image 1/5: Resume1.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to tesseract_output\\Resume1.txt\n",
            "--------------------------------------------------\n",
            "Processing image 2/5: Resume2.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to tesseract_output\\Resume2.txt\n",
            "--------------------------------------------------\n",
            "Processing image 3/5: Resume3.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to tesseract_output\\Resume3.txt\n",
            "--------------------------------------------------\n",
            "Processing image 4/5: Resume4.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to tesseract_output\\Resume4.txt\n",
            "--------------------------------------------------\n",
            "Processing image 5/5: Resume5.png\n",
            "Extracting text from image..\n",
            "Saved extracted text to tesseract_output\\Resume5.txt\n",
            "--------------------------------------------------\n",
            "Text Extraction Completed.\n",
            "Total time taken: 13.750824928283691 seconds\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import pytesseract\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "import time\n",
        "\n",
        "input_folder_path = \"processed_images\"\n",
        "output_folder_path = \"tesseract_output\"\n",
        "start_time = time.time()\n",
        "\n",
        "if os.makedirs(output_folder_path, exist_ok=True):\n",
        "  print(f\"Created folder: {output_folder_path}\")\n",
        "\n",
        "total_images = sum(1 for entry in os.scandir(input_folder_path))\n",
        "print(f\"Total images in folder: {total_images}\")\n",
        "\n",
        "for i, image_name in enumerate(os.listdir(input_folder_path)[:20], 1):\n",
        "  print(f\"Processing image {i}/{total_images}: {image_name}\")\n",
        "  image_path = os.path.join(input_folder_path, image_name)\n",
        "  print(\"Extracting text from image..\")\n",
        "  text = pytesseract.image_to_string(Image.open(image_path))\n",
        "  output_path = os.path.join(output_folder_path, image_name.replace(\".png\", \".txt\"))\n",
        "  with open(output_path, \"w\") as f:\n",
        "    f.write(text)\n",
        "\n",
        "  print(f\"Saved extracted text to {output_path}\")\n",
        "  print(\"-\"*50)\n",
        "\n",
        "print(\"Text Extraction Completed.\")\n",
        "print(f\"Total time taken: {time.time() - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqJWrXBuz8ab"
      },
      "source": [
        "## Now that all the text is in .txt files, we can pass all the info into an LLM and extract \"information\" from our \"data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tLtC-yKFz7Jy"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Extract key information from the given resume text.\n",
        "Information to be extracted: Position, skills, summary, work_experience.\n",
        "\n",
        "The text has been extracted from a resume using Tesseract OCR. Use only this text to extract information.\n",
        "Do NOT make up or generate any data. If a field is not present in the text, leave it as a blank string (\"\").\n",
        "\n",
        "For the \"work_experience\" field, summarize the person's experience into a short paragraph highlighting their key roles, achievements, and duration, based only on the extracted text.\n",
        "\n",
        "Always give your response in the following JSON format:\n",
        "\n",
        "{\n",
        "    \"Position\": \"\",\n",
        "    \"skills\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"work_experience\": \"\"\n",
        "}\n",
        "\n",
        "Respond strictly in the specified JSON format without adding any extra commentary or explanation.\n",
        "\n",
        "Here is the extracted text:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u8RX6D1Y012d"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "load_dotenv(find_dotenv(), override=True)\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import json\n",
        "import time\n",
        "\n",
        "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35xRRKT-088H",
        "outputId": "209dec97-f731-4e35-a687-30ad54573377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensured folder exists: json_output\n",
            "Total images in folder: 5\n",
            "Processing image 1/5: Resume1.png\n",
            "Loading image: processed_images\\Resume1.png\n",
            "Loading extracted text: tesseract_output\\Resume1.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1275\n",
            "Thoughts Token Count: 716\n",
            "Output Token Count: 235\n",
            "Total Token Count: 2226\n",
            "Saved extracted information to json_output\\Resume1.json\n",
            "--------------------------------------------------\n",
            "Processing image 2/5: Resume2.png\n",
            "Loading image: processed_images\\Resume2.png\n",
            "Loading extracted text: tesseract_output\\Resume2.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1229\n",
            "Thoughts Token Count: 1714\n",
            "Output Token Count: 329\n",
            "Total Token Count: 3272\n",
            "Saved extracted information to json_output\\Resume2.json\n",
            "--------------------------------------------------\n",
            "Processing image 3/5: Resume3.png\n",
            "Loading image: processed_images\\Resume3.png\n",
            "Loading extracted text: tesseract_output\\Resume3.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1219\n",
            "Thoughts Token Count: 1362\n",
            "Output Token Count: 298\n",
            "Total Token Count: 2879\n",
            "Saved extracted information to json_output\\Resume3.json\n",
            "--------------------------------------------------\n",
            "Processing image 4/5: Resume4.png\n",
            "Loading image: processed_images\\Resume4.png\n",
            "Loading extracted text: tesseract_output\\Resume4.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1349\n",
            "Thoughts Token Count: 2484\n",
            "Output Token Count: 249\n",
            "Total Token Count: 4082\n",
            "Saved extracted information to json_output\\Resume4.json\n",
            "--------------------------------------------------\n",
            "Processing image 5/5: Resume5.png\n",
            "Loading image: processed_images\\Resume5.png\n",
            "Loading extracted text: tesseract_output\\Resume5.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1376\n",
            "Thoughts Token Count: 1087\n",
            "Output Token Count: 431\n",
            "Total Token Count: 2894\n",
            "Saved extracted information to json_output\\Resume5.json\n",
            "--------------------------------------------------\n",
            "Information Extraction Completed.\n",
            "Total time taken: 377.3705909252167 seconds\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "image_folder_path = \"processed_images\"\n",
        "text_folder_path = \"tesseract_output\"\n",
        "output_folder_path = \"json_output\"\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "print(f\"Ensured folder exists: {output_folder_path}\")\n",
        "\n",
        "total_images = sum(1 for entry in os.scandir(image_folder_path))\n",
        "print(f\"Total images in folder: {total_images}\")\n",
        "\n",
        "for i, image_name in enumerate(os.listdir(image_folder_path)[:20], 1):\n",
        "    print(f\"Processing image {i}/{total_images}: {image_name}\")\n",
        "    image_path = os.path.join(image_folder_path, image_name)\n",
        "    print(f\"Loading image: {image_path}\")\n",
        "\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "    # Handle both .png and .jpg\n",
        "    base_name, _ = os.path.splitext(image_name)\n",
        "    text_path = os.path.join(text_folder_path, base_name + \".txt\")\n",
        "\n",
        "    print(f\"Loading extracted text: {text_path}\")\n",
        "    with open(text_path, \"r\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    print(\"Extracting information from image and text..\")\n",
        "\n",
        "    prompt_with_text = prompt + text\n",
        "\n",
        "    contents = [\n",
        "        image,\n",
        "        {\"text\": prompt_with_text}\n",
        "    ]\n",
        "    response = model.generate_content(\n",
        "        contents=contents\n",
        "    )\n",
        "\n",
        "    # Access the usage_metadata attribute\n",
        "    usage_metadata = response.usage_metadata\n",
        "    print(f\"Input Token Count: {usage_metadata.prompt_token_count}\")\n",
        "    print(f\"Thoughts Token Count: {response.usage_metadata.thoughts_token_count}\")\n",
        "    print(f\"Output Token Count: {usage_metadata.candidates_token_count}\")\n",
        "    print(f\"Total Token Count: {usage_metadata.total_token_count}\")\n",
        "\n",
        "    # ---- Safe response parsing ----\n",
        "    response_text = None\n",
        "    if hasattr(response, \"text\") and response.text:\n",
        "        response_text = response.text\n",
        "    elif hasattr(response, \"candidates\") and response.candidates:\n",
        "        parts = response.candidates[0].content.parts\n",
        "        if parts and hasattr(parts[0], \"text\"):\n",
        "            response_text = parts[0].text\n",
        "\n",
        "    if response_text is None:\n",
        "        print(\"⚠️ No text returned from model. Skipping this file.\")\n",
        "        continue\n",
        "\n",
        "    # Clean and parse JSON safely\n",
        "    response_text = response_text.replace('```json', '').replace('```', '')\n",
        "\n",
        "    try:\n",
        "        extracted_information = json.loads(response_text)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"⚠️ Failed to decode JSON for {image_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Save JSON with correct name\n",
        "    output_path = os.path.join(output_folder_path, base_name + \".json\")\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(extracted_information, f, indent=4)\n",
        "\n",
        "    print(f\"Saved extracted information to {output_path}\")\n",
        "    print(\"-\" * 50)\n",
        "    time.sleep(60)\n",
        "\n",
        "print(\"Information Extraction Completed.\")\n",
        "print(f\"Total time taken: {time.time() - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
